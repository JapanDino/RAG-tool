# План разработки по ТЗ: RAG‑разметка с привязкой к таксономии Блума (и удобное приложение для учителя)

Источник требований: `@ТЗ_на_RAG_разметку_с_привязкой_к_таксономии_Блума.docx`.

## 1) Цель конечного продукта

Приложение для учителей, которое:
- принимает образовательный текст (вставка/файл `.txt`);
- выделяет **узлы знаний** (смысловые единицы);
- присваивает каждому узлу **1+ уровней таксономии Блума** с вероятностями (multi‑label);
- сохраняет узлы в базу (RAG‑совместимую: текст + embedding + метаданные);
- показывает результаты как **интерактивный граф знаний** + табличный отчёт;
- позволяет фильтровать/искать/редактировать результаты.

Варианты поставки:
- **Desktop (.exe)** для удобства (Windows): один инсталлер/portable, локальный интерфейс.
- **Web (Docker)** как альтернативный способ развёртывания (для школ/серверов).

## 2) Архитектурная стратегия (рекомендуемая)

### 2.1 Desktop‑вариант (приоритет, .exe)
- UI: **Tauri** (или Electron) как оболочка “приложение”, внутри — web‑UI.
- Backend: текущий **FastAPI** (локально запускается внутри приложения/рядом).
- DB: для “одного учителя” разумно начать с **SQLite** (простая поставка), позже — Postgres/pgvector.
- Граф: визуализация на фронте (Cytoscape.js / Sigma.js / vis-network).

Почему так: учителю не нужно “поднимать сервер”, всё локально и удобно.

### 2.2 Web‑вариант (альтернатива)
- Docker Compose (у вас уже есть): API + Postgres + Redis + Frontend.

## 3) План работ (шаги)

Ниже — **пошаговый план**. У каждого шага есть критерий “готово”.

### Фаза A — Анализ ТЗ, базовые договорённости

**A1. Уточнение терминологии и форматов данных**
- Определить сущности: `Dataset`, `Document`, `Chunk`, `Node` (узел), `Edge` (ребро), `Annotation` (Bloom multi‑label).
- Утвердить формат результата: вероятности \([p_r, p_u, p_a, p_an, p_e, p_c]\) + top‑k.
- **Готово**: этот документ + схема данных (можно Mermaid ERD).

### Фаза B — Хранилище: узлы, вероятности, версии, рубрики

**B1. Привести модель данных к “узлам знаний” из ТЗ**
- Сейчас разметка идёт по `Chunk` и `BloomAnnotation`.
- Добавить сущность `KnowledgeNode` (или временно переиспользовать `Chunk` как узел, но в ТЗ узел ≠ чанк документа).
- **Готово**: миграция + модель + базовые CRUD API для узлов.

**B2. Версионирование и трассируемость**
- Для каждого результата хранить: версию модели/промпта, рубрику, timestamp.
- **Готово**: поля `version`, `rubric_id` реально используются при сохранении.

### Фаза C — Извлечение узлов (NER / semantic chunking)

**C1. MVP: извлечение узлов из текста**
- Реализовать пайплайн выделения “концептов/тем/навыков”:
  - эвристика (словари/частотность) как baseline;
  - опционально: spaCy/Stanza NER;
  - опционально: LLM‑экстракция.
- **Готово**: endpoint “extract nodes from text”, мини‑набор для проверки качества.

### Фаза D — Multi‑label классификация по Блуму (вероятности)

**D1. MVP multi‑label**
- Для каждого узла вернуть вероятности по 6 уровням.
- Источники:
  - baseline эвристика (глаголы/паттерны);
  - LLM с JSON‑ответом и валидацией.
- **Готово**: стабильный JSON, валидация, логирование, fallback.

**D2. Обучаемая модель (опционально, если нужен ML)**
- Собрать разметку минимум 100+ примеров (как в ТЗ).
- Обучить/тонко настроить модель (например, sentence‑transformers + classifier).
- **Готово**: отчёт по метрикам (Hamming Loss, F1 micro/macro).

### Фаза E — Граф знаний (узлы + рёбра)

**E1. Построение рёбер**
- Рёбра по семантической близости embedding’ов + co‑occurrence.
- Порог/топ‑N настраиваемый.
- **Готово**: API “get graph” возвращает nodes+edges.

**E2. Визуализация**
- Фронтенд‑граф: цвет по argmax(Bloom), градиент при multi‑label выше порога.
- Интерактивность: hover‑карточка (вероятности+контекст), фильтры по уровню.
- **Готово**: вкладка “Граф знаний” работает.

### Фаза F — UX для учителя (2 вкладки из ТЗ)

**F1. Экран “Анализ контента”**
- вставка текста / загрузка `.txt`;
- запуск анализа;
- таблица узлов: название, top‑уровни, вероятности, источник;
- экспорт (CSV/JSON).
- **Готово**: сценарий “вставил текст → получил узлы”.

**F2. Экран “Граф знаний”**
- визуализация + фильтры + поиск узла + легенда Блума.
- **Готово**: учитель может “прочитать” граф и отфильтровать.

### Фаза G — Desktop (.exe) упаковка

**G1. Выбор стека упаковки**
- Вариант 1 (быстро): Streamlit + PyInstaller (один процесс, проще).
- Вариант 2 (масштабируемо): Tauri/Electron + встроенный FastAPI.
- **Готово**: прототип сборки на Windows.

**G2. Инсталлер и обновления (опционально)**
- portable + installer, авто‑обновления.
- **Готово**: учитель запускает без установки Python/Node.

### Фаза H — Тестирование и приёмка

**H1. Автотесты**
- unit: валидация, метрики качества;
- интеграция: API сценарии “анализ/граф/экспорт”.
- **Готово**: зелёный CI.

**H2. Приёмка по критериям ТЗ**
- эксперт‑педагог проверяет адекватность узлов и уровней;
- проверка визуализации (цвета/градиенты/фильтры).
- **Готово**: чек‑лист приёмки.

## 4) Что уже сделано в текущем репозитории (по факту кода)

Сделано:
- Backend FastAPI + базовые сущности Dataset/Document/Chunk/Annotation/Job.
- Rubrics (CRUD + миграции + seed).
- Валидация LLM‑ответов + fallback.
- Метрики качества + endpoint статистики.
- API управления аннотациями (просмотр/обновление/удаление).
- LLM provider abstraction (heuristic/openai).
- Тесты: validation/quality/annotation management (нужно окружение с зависимостями).

Не сделано по ТЗ:
- извлечение “узлов знаний” из текста как отдельный модуль (NER/semantic chunking);
- multi‑label вероятности по 6 уровням (вместо single‑level аннотаций);
- формирование графа (edges) и UI графа;
- учительский UX (2 вкладки);
- упаковка в `.exe`.

## 5) Следующий шаг (следующая итерация)

Рекомендуемый следующий шаг: **C1 + D1** (MVP “вставил текст → получил узлы + вероятности”) + базовый экран “Анализ контента”.


